services:

  # =================================================================
  # OPTION E: The Powerhouse Architect (70B) - STABLE 128K
  # Llama 3.3 - Native BF16 Mode (No Crashes)
  # Fits on MI300X: Weights (140GB) + 128k Cache (40GB) = ~180GB / 192GB
  # =================================================================
  architect-solo-70b-llama:
    profiles: ["solo-architect-70b"]
    image: lmsysorg/sglang:v0.5.5.post3-rocm700-mi30x
    container_name: vylabs-architect-70b
    ipc: host
    network_mode: host
    privileged: true
    cap_add: [SYS_PTRACE]
    security_opt: [seccomp=unconfined]
    ulimits:
      memlock: -1
      stack: 67108864
      nofile: { soft: 1048576, hard: 1048576 }
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    volumes:
      - /mnt/scratch/huggingface:/root/.cache/huggingface
    environment:
      - HF_TOKEN=${HF_TOKEN}
      - SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN=1
      - HSA_NO_SCRATCH_RECLAIM=1
      - HF_HOME=/root/.cache/huggingface
      - GLOO_SOCKET_IFNAME=eth0
      - NCCL_SOCKET_IFNAME=eth0
      # [CRITICAL] Disable AITER to stop the dtype crash
      - SGLANG_USE_AITER=0
      - NCCL_MIN_NCHANNELS=112
      # Manage memory fragmentation for the massive 180GB allocation
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    command: >
      python3 -m sglang.launch_server
      --model-path meta-llama/Llama-3.3-70B-Instruct
      --tp 1 --host 0.0.0.0 --port 30001
      --mem-fraction-static 0.94
      --kv-cache-dtype bfloat16
      --context-length 128000
      --trust-remote-code
      --attention-backend triton
      --tool-call-parser llama3

  # =================================================================
  # OPTION F: The Open Heavyweight (72B) - 128K UNLOCKED
  # Qwen 2.5 72B - Force-Enables 128k Context via YaRN
  # Fits on MI300X: ~165GB VRAM used
  # =================================================================
  architect-solo-72b-qwen:
    profiles: ["solo-architect-72b"]
    image: lmsysorg/sglang:v0.5.5.post3-rocm700-mi30x
    container_name: vylabs-architect-72b
    ipc: host
    network_mode: host
    privileged: true
    cap_add: [SYS_PTRACE]
    security_opt: [seccomp=unconfined]
    ulimits:
      memlock: -1
      stack: 67108864
      nofile: { soft: 1048576, hard: 1048576 }
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    volumes:
      - /mnt/scratch/huggingface:/root/.cache/huggingface
    environment:
      - SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN=1
      - HSA_NO_SCRATCH_RECLAIM=1
      - HF_HOME=/root/.cache/huggingface
      - GLOO_SOCKET_IFNAME=eth0
      - NCCL_SOCKET_IFNAME=eth0
      - SGLANG_USE_AITER=0
      - NCCL_MIN_NCHANNELS=112
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - MAX_MCP_OUTPUT_TOKENS=8000
    command: >
      python3 -m sglang.launch_server
      --model-path Qwen/Qwen2.5-72B-Instruct
      --tp 1 --host 0.0.0.0 --port 30001
      --mem-fraction-static 0.92
      --kv-cache-dtype bfloat16
      --context-length 131072
      --trust-remote-code
      --attention-backend triton
      --chunked-prefill-size 8192
      --tool-call-parser qwen
      --json-model-override-args '{"rope_scaling": {"type": "yarn", "factor": 4.0, "original_max_position_embeddings": 32768}, "max_position_embeddings": 131072}'

  solo-architect-qwen3-next-80b-80k:
    profiles: ["solo-architect-qwen3-next-80b-80k"]
    image: lmsysorg/sglang:v0.5.5.post3-rocm700-mi30x
    container_name: architect-solo-qwen3-next-80b-80k
    ipc: host
    network_mode: host
    privileged: true
    cap_add: [SYS_PTRACE]
    security_opt: [seccomp=unconfined]
    ulimits:
      memlock: -1
      stack: 67108864
      nofile: { soft: 1048576, hard: 1048576 }
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    volumes:
      - /mnt/scratch/huggingface:/root/.cache/huggingface
    environment:
      - SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN=1
      - HSA_NO_SCRATCH_RECLAIM=1
      - HF_HOME=/root/.cache/huggingface
      - GLOO_SOCKET_IFNAME=eth0
      - NCCL_SOCKET_IFNAME=eth0
      - SGLANG_USE_AITER=0
      - SGLANG_USE_TRITON_FLASH_ATTN=1
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      - MAX_MCP_OUTPUT_TOKENS=8000
    command: >
      python3 -m sglang.launch_server
      --model-path Qwen/Qwen3-Next-80B-A3B-Thinking
      --tp 1 --host 0.0.0.0 --port 30002
      --quantization fp8
      --kv-cache-dtype bfloat16
      --context-length 81920
      --mem-fraction-static 0.92
      --trust-remote-code
      --attention-backend triton
      --disable-cuda-graph
      --chunked-prefill-size 16384
      --reasoning-parser qwen3
      --tool-call-parser qwen25

  # =================================================================
  # SERVICE: The Open Heavyweight (72B) - "IRONCLAD 160K"
  # Hardware: AMD MI300X (192GB VRAM)
  # Context: 160k (YaRN Factor 5.0)
  # Stability: Chunked Prefill enabled to prevent OOM on massive prompts
  # =================================================================
  architect-solo-72b-qwen-160K:
    profiles: ["solo-architect-72b-160k"]
    image: lmsysorg/sglang:v0.5.5.post3-rocm700-mi30x
    container_name: vylabs-architect-72b
    ipc: host
    network_mode: host
    privileged: true
    cap_add: [SYS_PTRACE]
    security_opt: [seccomp=unconfined]
    ulimits:
      memlock: -1
      stack: 67108864
      nofile: { soft: 1048576, hard: 1048576 }
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    volumes:
      - /mnt/scratch/huggingface:/root/.cache/huggingface
    environment:
      - SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN=1
      - HSA_NO_SCRATCH_RECLAIM=1
      - HF_HOME=/root/.cache/huggingface
      - GLOO_SOCKET_IFNAME=eth0
      - NCCL_SOCKET_IFNAME=eth0
      - SGLANG_USE_AITER=0
      - NCCL_MIN_NCHANNELS=112
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      # ---------------------------------------------------------
      # SAFETY LAYER: Prevent Tool Output Explosions (Context Debt)
      # ---------------------------------------------------------
      - MAX_MCP_OUTPUT_TOKENS=8000  # Hard cap for Router/Tools
    command: >
      python3 -m sglang.launch_server
      --model-path Qwen/Qwen2.5-72B-Instruct
      --tp 1 --host 0.0.0.0 --port 30001
      --mem-fraction-static 0.90
      --kv-cache-dtype bfloat16
      --context-length 163840
      --trust-remote-code
      --attention-backend triton
      --tool-call-parser qwen25
      --chunked-prefill-size 8192
      --enable-mixed-chunk
      --json-model-override-args '{"rope_scaling": {"type": "yarn", "factor": 5.0, "original_max_position_embeddings": 32768}, "max_position_embeddings": 163840}'

  architect-solo-dr1-distill-32b:
    profiles: ["solo-architect-32b"]
    image: lmsysorg/sglang:v0.5.5.post3-rocm700-mi30x
    container_name: vylabs-builder-solo
    ipc: host
    network_mode: host
    privileged: true
    cap_add: [SYS_PTRACE]
    security_opt: [seccomp=unconfined]
    ulimits:
      memlock: -1
      stack: 67108864
      nofile: { soft: 1048576, hard: 1048576 }
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    volumes:
      - /mnt/scratch/huggingface:/root/.cache/huggingface
    environment:
      - SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN=1
      - HSA_NO_SCRATCH_RECLAIM=1
      - HF_HOME=/root/.cache/huggingface
      - GLOO_SOCKET_IFNAME=eth0
      - NCCL_SOCKET_IFNAME=eth0
      # AITER is mandatory for DeepSeek-R1 performance
      - SGLANG_USE_AITER=1
      - NCCL_MIN_NCHANNELS=112
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    healthcheck:
      test: ["CMD-SHELL", "python3 -c \"import urllib.request; print(urllib.request.urlopen('http://localhost:30000/health').read())\" || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 20
      start_period: 45s
    command: >
      python3 -m sglang.launch_server
      --model-path deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
      --tp 1 --host 0.0.0.0 --port 30001
      --mem-fraction-static 0.80
      --kv-cache-dtype bfloat16
      --context-length 131072
      --trust-remote-code
      --attention-backend aiter
      --chunked-prefill-size 32768
      --tool-call-parser qwen

  # =================================================================
  # OPTION A: The Efficient Strategist (14B)
  # Distilled from Qwen 2.5 - Fast & Logic Heavy
  # =================================================================
  architect-solo-14b-qwen:
    profiles: ["solo-architect-14b"]
    image: lmsysorg/sglang:v0.5.5.post3-rocm700-mi30x
    container_name: vylabs-architect-14b
    ipc: host
    network_mode: host
    privileged: true
    cap_add: [SYS_PTRACE]
    security_opt: [seccomp=unconfined]
    ulimits:
      memlock: -1
      stack: 67108864
      nofile: { soft: 1048576, hard: 1048576 }
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    volumes:
      - /mnt/scratch/huggingface:/root/.cache/huggingface
    environment:
      - SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN=1
      - HSA_NO_SCRATCH_RECLAIM=1
      - HF_HOME=/root/.cache/huggingface
      - GLOO_SOCKET_IFNAME=eth0
      - NCCL_SOCKET_IFNAME=eth0
      - SGLANG_USE_AITER=1
      - NCCL_MIN_NCHANNELS=112
    command: >
      python3 -m sglang.launch_server
      --model-path deepseek-ai/DeepSeek-R1-Distill-Qwen-14B
      --tp 1 --host 0.0.0.0 --port 30001
      --mem-fraction-static 0.80
      --kv-cache-dtype bfloat16
      --context-length 131072
      --trust-remote-code
      --attention-backend aiter
      --tool-call-parser qwen

  # =================================================================
  # OPTION B: The Standard Bearer (8B)
  # Distilled from Llama 3.1 - Broad Compatibility
  # =================================================================
  architect-solo-8b-llama:
    profiles: ["solo-architect-8b"]
    image: lmsysorg/sglang:v0.5.5.post3-rocm700-mi30x
    container_name: vylabs-architect-8b
    ipc: host
    network_mode: host
    privileged: true
    cap_add: [SYS_PTRACE]
    security_opt: [seccomp=unconfined]
    ulimits:
      memlock: -1
      stack: 67108864
      nofile: { soft: 1048576, hard: 1048576 }
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    volumes:
      - /mnt/scratch/huggingface:/root/.cache/huggingface
    environment:
      - SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN=1
      - HSA_NO_SCRATCH_RECLAIM=1
      - HF_HOME=/root/.cache/huggingface
      - GLOO_SOCKET_IFNAME=eth0
      - NCCL_SOCKET_IFNAME=eth0
      - SGLANG_USE_AITER=1
    command: >
      python3 -m sglang.launch_server
      --model-path deepseek-ai/DeepSeek-R1-Distill-Llama-8B
      --tp 1 --host 0.0.0.0 --port 30001
      --mem-fraction-static 0.80
      --kv-cache-dtype bfloat16
      --context-length 131072
      --trust-remote-code
      --attention-backend aiter
      --tool-call-parser llama3

  # =================================================================
  # OPTION C: The Creative Multimodal (27B)
  # Gemma 3 - Vision & Text (Experimental on SGLang)
  # =================================================================
  architect-solo-27b-gemma:
    profiles: ["solo-architect-27b"]
    image: lmsysorg/sglang:v0.5.5.post3-rocm700-mi30x
    container_name: vylabs-architect-27b
    ipc: host
    network_mode: host
    privileged: true
    cap_add: [SYS_PTRACE]
    security_opt: [seccomp=unconfined]
    ulimits:
      memlock: -1
      stack: 67108864
      nofile: { soft: 1048576, hard: 1048576 }
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    volumes:
      - /mnt/scratch/huggingface:/root/.cache/huggingface
    environment:
      - SGLANG_ALLOW_OVERWRITE_LONGER_CONTEXT_LEN=1
      - HSA_NO_SCRATCH_RECLAIM=1
      - HF_HOME=/root/.cache/huggingface
      - GLOO_SOCKET_IFNAME=eth0
      - NCCL_SOCKET_IFNAME=eth0
      # [NOTE] Gemma 3 may require disabling AITER if kernels mismatch
      - SGLANG_USE_AITER=0
    command: >
      python3 -m sglang.launch_server
      --model-path google/gemma-3-27b-it
      --tp 1 --host 0.0.0.0 --port 30001
      --mem-fraction-static 0.80
      --kv-cache-dtype bfloat16
      --context-length 131072
      --trust-remote-code
